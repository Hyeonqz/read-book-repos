# 4장 - 처리율 제한 장치의 설계
네트워크 시스템에서 처리율 제한 장치라는 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치다 <br>
http 를 예로 들면 이 장치는 특정 기간 내에 전송되는 클라이언트의 요청 횟수를 제한한다 <br>
API 요청 횟수가 제한 장치에 정의된 임계치를 넘어서면 추가로 도달한 모든 호출은 처리가 중단된다 <br>
- 사용자는 초당 2회 이상 새 글을 올릴 수 없다.
- 같은 IP 주소로는 하루에 10개 이상의 계정을 생성할 수 없다.
- 같은 디바이스로는 주당 5회 이상 리워드를 요청할 수 없다.

api 처리율 제한 장치를 두면 좋은 점을 살펴보자 <br>
- DoS 공격을 방지할 수 있다.
  - 처리율 제한 장치는 추가 요청에 대해서는 처리를 중단함으로 써 DoS 공격을 방지한다.
- 비용을 절감한다.
  - 추가 요청에 대한 처리를 제한하면 서버를 많이 두지 않아도 되고, 우선 순위가 높은 API 에 더 많은 자원을 할당할 수 있다.
  - 특히 처리율 제한은 제3자 API 에 사용료를 지불하고 있는 회사들에게는 중요하다. ex) API 호출에 횟수에 따라 금액이 부과되는 것 
- 서버 과부하를 막는다.


#### 1단계 문제 이해 및 설계 범위 확정
처리율 제한 장치를 구현하는 데는 여러 알고리즘이 있다 <br>

#### 2단계 개략적 설계안 제시 및 동의 구하기
일단 시작은 일반적인 클라이언트-서버 간의 통신 모델을 사용하도록 하자 <br>

처리율 제한장치는, 클라이언트에 둘 수도있고 서버에 둘 수도있다 <br>
일반적으로 클라리언트는 요청을 위변조 할 수 있기에 서버쪽에 두는게 올바른 판단같다 <br>
그리고 서버에 처리율 제한 장치를 둬도 되고, 미들웨어를 클라이언트-서버 중간에 두고 통제하도록 할 수 있다 <br>

보통 MSA 환경에서는 처리율 제한 장치는 보통 API Gateway 라 불리는 컴포넌트에 구현된다 <br>

API Gateway 는 ssl 종단, 사용자 인증, ip 허용, 관리 등등 위탁 서비스이다 <br>
지금은 API Gateway 는 미들웨어 정도로만 알고 있자 <br>

처리율 제한 서비스를 만드는 것은 시간이 든다 <br>
그러므로 상용 API Gateway 를 사용하는 것도 방법중 하나이다 <br>

### 처리율 제한 알고리즘
- 토큰 버킷 
- 누출 버킷
- 고정 윈도 카운터
- 이동 윈도 로그
- 이동 윈도 카운터


#### 토큰 버킷
지정된 용량을 갖는 컨테이너 이다, 이 버킷에는 사전 설정된 양의 토큰이 주기적으로 채워진다 <br>
매 요청마다 컨테이너에서 토큰을 1개씩 꺼내서 시스템에 같이 요청한다. 만약에 시스템에 토큰이 전달되지 않으면 유효하지 않은 것으로 판단하고 그 요청은 버려진다 <br>

#### 누출 버킷
위 알고리즘은 Queue 와 같다 FIFO 로 구현된다 <br>
- 요청이 오면 큐를 체크 한다. 빈자리가 있는 경우 큐에 요청을 추가한다.
- 큐가 가득차 있다면 새 요청은 버린다.
- 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.


#### 고정 윈도 카운터
타임라임을 고정된 윈도우로 나누고 각 윈도마다 카운터를 붙인다. <br>
요청이 접수 될 때 마다 카운터의 값은 1씩 증가한다 <br>
위 카운터 값이 설정해둔 임계치에 도달하면 그 이후 요청은 버려진다 <br>

만약 윈도 경계 부근에 트래픽이 집중된다면 시스템 설정보다 더 많은 요청을 처리하게 될 것이다 <br>

#### 이동 윈도 로그
- 위 알고리즘은 요청의 타임스태프를 추적한다.
  - 타임스탬프 데이터는 보통 레디스의 정렬 집합 같은 캐시에 보관한다.
- 새 요청이 오면 만료된 타임스태프는 제거한다.


#### 이동 윈도 카운터
고정윈도 카운터 + 이동 윈도 로그 알고리즘을 합친 내용이다 <br>

그럼 처리율 제한 장치 관련 카운터를 어떻게 보관할 것인가? <br>
db 는 디스크 접근 때문에 느리니까 사용하면 안될 것이다. 메모리상에서 동작하는 캐시가 바람직한데, 빠른데다 시간에 기반한 만료 정책을 지원하기 때문이다 <br>
ex) redis 사용 <br>

### 상세 설계
#### 처리율 제한 규칙 -> Lyft(리프트)

#### 분산환경에서의 처리율 제한 장치 구현
단일 서버에는 처리율 제한 장치 구현이 어렵지 않다 <br>
하지만 다중화 서버에서 멀티 스레드를 지원하도록 시스템을 확장하는 것은 2가지 문제를 풀어야 한다 <br>
- race Condition
- synchronization

#### raceCondition
- redis 에서 카운터의 값을 읽어온다.
- counter +1 의 값이 임계치를 넘는지 체크
- 넘지 않으면 redis 보관된 counter++ 을 한다.

raceCondition 을 해결하는 가장 널리 알려진 해결책은 Lock 이다 <br>
하지만 Lock 은 시스템의 성능을 떨어뜨린다는 문제가 있다 <br>

redis 설계는 Lock 을 제외하고 루아 스크립트, 정렬 집합이라 불리는 레디스 자료구조를 사용하여 해결할 수 있다 <br>

#### synchronization
분산환경에서 동기화는 아주 중요한 기술이다 <br>
웹 계층은 무상태이므로 클라이언트 요청을 각각 다르게 관리할 수 있다 <br>

위 같은 상황을 간단하게 해결하는 방법은 로드밸런서의 '스티키 세션' 을 사용하여 같은 클라이언트 요청은 항상 서버로 보낼 수 있도록 하는 것이다 <br>
하지만 위 방법은 규모 확장에 좋지 않고 더 나은 해결책은 레디스와 같은 중앙 집중형 데이터 저장소를 쓰는 것이다 <br>
> 클라1,클라2 -> 처리율 제한 장치1, 처리율 제한 장치2 -> 레디스


#### 성능 최적화
- 우선 여러 데이터 센터를 지원하는 문제는 처리율 제한 장치에 매우 중요한 문제이다
- 데이터 동기화 간에 일관성 모델을 사용하는 것이다.

#### 모니터링
처리율 제한 장치를 설치한 이후에는 효과적으로 동작하고 있는지 보기 위해 데이터를 모을 필요가 있다 <br>

참고로 처리율 제한 장치는 어플리테이션 계층(=https) 에서만 가능한게 아니라 3계층(=네트워크 계층) 에서도 가능하며 다른 게층에서도 가능 할 것 이다 <br>